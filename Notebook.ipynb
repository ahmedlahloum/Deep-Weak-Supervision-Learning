{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small data and deep learning\n",
    "This mini-project proposes to study several techniques for improving challenging context, in which few data and resources are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Assume we are in a context where few \"gold\" labeled data are available for training, say $\\mathcal{X}_{\\text{train}}\\triangleq\\{(x_n,y_n)\\}_{n\\leq N_{\\text{train}}}$, where $N_{\\text{train}}$ is small. A large test set $\\mathcal{X}_{\\text{test}}$ is available. A large amount of unlabeled data, $\\mathcal{X}$, is available. We also assume that we have a limited computational budget (e.g., no GPUs).\n",
    "\n",
    "For each question, write a commented *Code* or a complete answer as a *Markdown*. When the objective of a question is to report a CNN accuracy, please use the following format to report it, at the end of the question:\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   XXX  | XXX | XXX | XXX |\n",
    "\n",
    "If applicable, please add the field corresponding to the  __Accuracy on Full Data__ as well as a link to the __Reference paper__ you used to report those numbers. (You do not need to train a CNN on the full CIFAR10 dataset)\n",
    "\n",
    "In your final report, please keep the logs of each training procedure you used. We will only run this jupyter if we have some doubts on your implementation. \n",
    "\n",
    "__The total file sizes should not exceed 2MB. Please name your notebook (LASTNAME)\\_(FIRSTNAME).ipynb, zip/tar it with any necessary files required to run your notebook, in a compressed file named (LASTNAME)\\_(FIRSTNAME).X where X is the corresponding extension. Zip/tar files exceeding 2MB will not be considered for grading. Submit the compressed file via the submission link provided on the website of the class.__\n",
    "\n",
    "You can use https://colab.research.google.com/ to run your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set creation\n",
    "__Question 1:__ Propose a dataloader or modify the file located at https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py in order to obtain a training loader that will only use the first 100 samples of the CIFAR-10 training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform_224 = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True , transform = transform) \n",
    "testset = CIFAR10(root='./data', train=False, download=True , transform = transform)\n",
    "\n",
    "class SubsetSampler(Sampler):\n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(torch.arange(self.number))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.number\n",
    "\n",
    "sampler_100 = SubsetSampler(100)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=10, sampler = sampler_100, shuffle=False)\n",
    "trainevalloader = DataLoader(trainset, batch_size=100, sampler = sampler_100, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our dataset $\\mathcal{X}_{\\text{train}}$, it will be used until the end of this project. The remaining samples correspond to $\\mathcal{X}$. The testing set $\\mathcal{X}_{\\text{test}}$ corresponds to the whole testing set of CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing procedure\n",
    "__Question 2:__ Explain why the evaluation of the training procedure is difficult. Propose several solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation of the training procedure is difficult because of the small amount of labeled set we have. This is problematic because we don't have enough observations to estimate properly the quality of the convergence of the algorithm or to estimate the gradients during the training procedure. Also, the small amount of data can cause the algorithm to overfit very easily.\n",
    "\n",
    "Some solutions to this problem can be to use strong regularization (Through weights regularization and Dropouts for example) and to use weak supervision algorithms that can use unlabeled data to improve the model and have a better idea of te training. Also, a good way to evaluate the training would be to have access to a test set ( or a way to test the performances of the trained model) to have a good idea of the performance of the model. This is our case since we can use a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw approach: the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the goal is to train a CNN on $\\mathcal{X}_{\\text{train}}$ and compare its performances with reported number from the litterature. You will have to re-use and/or design a standard classification pipeline. You should optimize your pipeline to obtain the best performances (image size, data augmentation by flip, ...).\n",
    "\n",
    "The key ingredients for training a CNN are the batch size, as well as the learning rate schedule, i.e. how to decrease the learning rate as a function of the number of epochs. A possible schedule is to start the learning rate at 0.1 and decreasing it every 30 epochs by 10. In case of divergence, reduce the laerning rate. A potential batch size could be 10, yet this can be cross-validated.\n",
    "\n",
    "You can get some baselines accuracies in this paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Keshari_Learning_Structure_and_CVPR_2018_paper.pdf. Obviously, it is a different context, as those researchers had access to GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train_loop(epochs , trainloader , testloader , trainevalloader , optimizer , net , criterion , verbose):\n",
    "    \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        if epoch % verbose == verbose - 1 : \n",
    "            print('[Epoch %d] loss: %.3f' % (epoch + 1, running_loss / 100))\n",
    "            \n",
    "            \n",
    "    print('Training Finished')\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        print('Results on train set :')\n",
    "\n",
    "        _, predicted = torch.max( net(list(trainevalloader)[0][0]) , 1)\n",
    "        correct = torch.sum(predicted == list(trainevalloader)[0][1])\n",
    "        total = 100\n",
    "        print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "        print('Results on test set :')\n",
    "\n",
    "        predictions , true_labs = [] , []\n",
    "\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max( outputs , 1)\n",
    "            predictions = predictions + list(predicted)\n",
    "            true_labs = true_labs + list(labels)\n",
    "\n",
    "\n",
    "        correct = torch.sum(torch.tensor(predictions) == torch.tensor(true_labs))\n",
    "        total = 10000\n",
    "        print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss: 0.159\n",
      "[Epoch 20] loss: 0.010\n",
      "[Epoch 30] loss: 0.007\n",
      "[Epoch 40] loss: 0.012\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 98 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 18 %\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "train_loop(40 , trainloader , testloader , trainevalloader , optimizer , cnn , criterion , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   CNN  | 100 | 100% |21%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3:__ Write a classification pipeline for $\\mathcal{X}_{\\text{train}}$, train from scratch and evaluate a *ResNet-18* architecture specific to CIFAR10 (details about the ImageNet model can be found here: https://arxiv.org/abs/1409.1556 ). If possible, please report the accuracy obtained on the whole dataset, as well as the reference paper/GitHub link you might have used.\n",
    "\n",
    "*Hint:* You can re-use the following code: https://github.com/kuangliu/pytorch-cifar. During a training of 10 epochs, a batch size of 10 and a learning rate of 0.01, one obtains 40% accuracy on $\\mathcal{X}_{\\text{train}}$ (~2 minutes) and 20% accuracy on $\\mathcal{X}_{\\text{test}}$ (~5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 10] loss: 0.051\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 75 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 18 %\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18(pretrained = False)\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True , transform = transform_224) \n",
    "testset = CIFAR10(root='./data', train=False, download=True , transform = transform_224)\n",
    "sampler_100 = SubsetSampler(100)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=10, sampler = sampler_100, shuffle=False)\n",
    "trainevalloader = DataLoader(trainset, batch_size=100, sampler = sampler_100, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=10, shuffle=False)\n",
    "\n",
    "train_loop(10 , trainloader , testloader  , trainevalloader , optimizer , resnet18 , criterion , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   Resnet18  | 10 | 75% | 18% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-like architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4:__ Same question as before, but with a *VGG*. Which model do you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss: 0.248\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 17 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "vgg11 = models.vgg11(pretrained = False)\n",
    "\n",
    "optimizer = optim.SGD(vgg11.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "train_loop(10 , trainloader , testloader,  trainevalloader , optimizer , vgg11 , criterion , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   VGG11  | 10 | 17% | 10% |\n",
    "\n",
    "Based on these results, the best choice appears to be the Resnet Architechture, although the VGG architechture shoud be trained more (the training & evaluation time makes it difficult on the current setup.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose to use pre-trained models on a classification and generative task, in order to improve the results of our setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use some pre-trained models on ImageNet and see how well they compare on CIFAR. A list is available on: https://pytorch.org/docs/stable/torchvision/models.html.\n",
    "\n",
    "__Question 5:__ Pick a model from the list above, adapt it to CIFAR and retrain its final layer (or a block of layers, depending on the resources to which you have access to). Report its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss: 0.002\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 35 %\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.require_grad = False\n",
    "    \n",
    "model.fc = nn.Linear(512, 10)\n",
    "\n",
    "train_loop(10 , trainloader , testloader , trainevalloader , optimizer , model , criterion , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|  Pretrained Resnet18  | 10 | 100% | 35% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGan features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs correspond to an unsupervised technique for generating images. In https://arxiv.org/pdf/1511.06434.pdf, Sec. 5.1 shows that the representation obtained from the Discriminator has some nice generalization properties on CIFAR10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 6:__  Using for instance a pretrained model from https://github.com/soumith/dcgan.torch combined with https://github.com/pytorch/examples/tree/master/dcgan, propose a model to train on $\\mathcal{X}_{\\text{train}}$. Train it and report its accuracy.\n",
    "\n",
    "*Hint:* You can use the library: https://github.com/bshillingford/python-torchfile to load the weights of a model from torch(Lua) to pytorch(python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part was run under Python 2.7\n",
    "# !wget https://drive.google.com/open?id=1wz0Ke0TL8J9x2AkfpYTBII0UfO_OPVgH\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchfile\n",
    "\n",
    "class DiscriminatorFeatures(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(DiscriminatorFeatures, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.ndf = ndf\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 1, 0, bias=False),\n",
    "            )\n",
    "        \n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 320)\n",
    "\n",
    "def load_feature_extractor():\n",
    "    path = \"landscapes_776_net_D_cpu.t7\"\n",
    "    lua_weights = torchfile.load(path)\n",
    "    feature_extractor = DiscriminatorFeatures(3, 40)\n",
    "    \n",
    "    feature_extractor.main._modules['0'].weight.data = torch.FloatTensor(lua_weights[b'modules'][0][b'weight'])\n",
    "    feature_extractor.main._modules['2'].weight.data = torch.FloatTensor(lua_weights[b'modules'][2][b'weight'])\n",
    "    feature_extractor.main._modules['3'].weight.data = torch.FloatTensor(lua_weights[b'modules'][3][b'weight'])\n",
    "    feature_extractor.main._modules['5'].weight.data = torch.FloatTensor(lua_weights[b'modules'][5][b'weight'])\n",
    "    feature_extractor.main._modules['6'].weight.data = torch.FloatTensor(lua_weights[b'modules'][6][b'weight'])\n",
    "    feature_extractor.main._modules['8'].weight.data = torch.FloatTensor(lua_weights[b'modules'][8][b'weight'])\n",
    "    \n",
    "    return feature_extractor\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.feature_extractor = load_feature_extractor()\n",
    "        self.fc = nn.Linear(320, 10)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        h = self.feature_extractor(input)\n",
    "        return self.fc(h)\n",
    "\n",
    "    \n",
    "model = Classifier()\n",
    "\n",
    "for param in model.feature_extractor.parameters():\n",
    "    param.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(root='./data', train=True, download=True , transform = transform) \n",
    "testset = CIFAR10(root='./data', train=False, download=True , transform = transform)\n",
    "trainloader = DataLoader(trainset, batch_size=10, sampler = sampler_100, shuffle=False)\n",
    "trainevalloader = DataLoader(trainset, batch_size=100, sampler = sampler_100, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] loss: 0.043\n",
      "[Epoch 20] loss: 0.000\n",
      "[Epoch 30] loss: 0.000\n",
      "[Epoch 40] loss: 0.000\n",
      "[Epoch 50] loss: 0.000\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 100 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 21 %\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "train_loop(50 , trainloader , testloader, trainevalloader , optimizer , model , criterion , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|  DCGAN Features  | 10 | 100% | 21% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating *a priori*\n",
    "Geometrical *a priori* are appealing for image classification tasks. For now, we only consider linear transformations $\\mathcal{T}$ of the inputs $x:\\mathbb{S}^2\\rightarrow\\mathbb{R}$ where $\\mathbb{S}$ is the support of an image, meaning that:\n",
    "\n",
    "$$\\forall u\\in\\mathbb{S}^2,\\mathcal{T}(\\lambda x+\\mu y)(u)=\\lambda \\mathcal{T}(x)(u)+\\mu \\mathcal{T}(y)(u)\\,.$$\n",
    "\n",
    "For instance if an image had an infinite support, a translation $\\mathcal{T}_a$ by $a$ would lead to:\n",
    "\n",
    "$$\\forall u, \\mathcal{T}_a(x)(u)=x(u-a)\\,.$$\n",
    "\n",
    "Otherwise, one has to handle several boundary effects.\n",
    "\n",
    "__Question 7:__ Explain the issues when dealing with translations, rotations, scaling effects, color changes on $32\\times32$ images. Propose several ideas to tackle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 8:__ Propose a set of geometric transformation beyond translation, and incorporate them in your training pipeline. Train the model of the __Question 3__ and __Question 4__ with them and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 10] loss: 0.173\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 42 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 18 %\n",
      "[Epoch 10] loss: 0.254\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 11 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(15, translate=(.2 , .2), \n",
    "                               scale= (.7 , 1.3) , shear= 15, resample=False, fillcolor=0),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True , transform = train_transforms) \n",
    "trainevalset = CIFAR10(root='./data', train=True, download=True , transform = transform_224)\n",
    "testset = CIFAR10(root='./data', train=False, download=True , transform = transform_224)\n",
    "\n",
    "sampler_100 = SubsetSampler(100)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=10, sampler = sampler_100, shuffle=False)\n",
    "trainevalloader = DataLoader(trainevalset, batch_size=100, sampler = sampler_100, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "\n",
    "resnet18 = models.resnet18(pretrained = False)\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=0.01, momentum=0.9)\n",
    "train_loop(10 , trainloader , testloader,trainevalloader, optimizer , resnet18 , criterion , 10)\n",
    "\n",
    "vgg11 = models.vgg11(pretrained = False)\n",
    "optimizer = optim.SGD(vgg11.parameters(), lr=0.01, momentum=0.9)\n",
    "train_loop(10 , trainloader , testloader, trainevalloader, optimizer , vgg11 , criterion , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|  Resnet 18 | 10 | 42% | 18% |\n",
    "|  VGG 11  | 10 | 11% | 10% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelets\n",
    "\n",
    "__Question 9:__ Use a Scattering Transform as an input to a ResNet-like architecture. You can find a baseline here: https://arxiv.org/pdf/1703.08961.pdf.\n",
    "\n",
    "*Hint:* You can use the following package: https://www.kymat.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kymat.io/gallery_2d/cifar_resnet.html#sphx-glr-gallery-2d-cifar-resnet-py\n",
    "\n",
    "\n",
    "from kymatio import Scattering2D\n",
    "import kymatio.datasets as scattering_datasets\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Scattering2dResNet(nn.Module):\n",
    "    def __init__(self, in_channels,  k=2, n=4, num_classes=10):\n",
    "        super(Scattering2dResNet, self).__init__()\n",
    "        self.inplanes = 16 * k\n",
    "        self.ichannels = 16 * k\n",
    "        self.K = in_channels\n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels, eps=1e-5, affine=False),\n",
    "            nn.Conv2d(in_channels, self.ichannels,\n",
    "                  kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.ichannels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = self._make_layer(BasicBlock, 32 * k, n)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 64 * k, n)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(2)\n",
    "        self.fc = nn.Linear(64 * k * 4, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), self.K, 8, 8)\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 10] loss: 0.034\n",
      "Training Finished\n",
      "Results on train set :\n",
      "Accuracy of the network on the train images: 85 %\n",
      "Results on test set :\n",
      "Accuracy of the network on the test images: 19 %\n"
     ]
    }
   ],
   "source": [
    "from kymatio import Scattering2D\n",
    "\n",
    "scattering = Scattering2D(J=2, shape=(32, 32))\n",
    "\n",
    "scat_transform = transforms.Compose([transforms.ToTensor(),\n",
    "     scattering])\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True , transform = scat_transform) \n",
    "testset = CIFAR10(root='./data', train=False, download=True , transform = scat_transform)\n",
    "\n",
    "\n",
    "sampler_100 = SubsetSampler(100)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=10, sampler = sampler_100, shuffle=False)\n",
    "trainevalloader = DataLoader(trainset, batch_size=100, sampler = sampler_100, shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=10, shuffle=False)\n",
    "\n",
    "resnet = Scattering2dResNet(in_channels = 81*3)\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loop(10 , trainloader , testloader , trainevalloader , optimizer , resnet , criterion , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|  Scattering Resnet  | 10 | 85% | 19% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weakly supervised techniques permit to tackle the issue of labeled data. An introduction to those techniques can be found here: https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html.\n",
    "\n",
    "__(Open) Question 10:__ Pick a weakly supervised method that will potentially use $\\mathcal{X}\\cup\\mathcal{X}_{\\text{train}}$ to train a representation (a subset of $\\mathcal{X}$ is also fine). Evaluate it and report the accuracies. You should be careful in the choice of your method, in order to avoid heavy computational effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 11:__ Write a short report explaining the pros and the cons of each methods that you implemented. 25% of the grade of this project will correspond to this question, thus, it should be done carefully. In particular, please add a plot that will summarize all your numerical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this Homework, we tested several technics to compensate the lack of labeled training data.\n",
    "\n",
    "The first idea was to simply train a model from scratch, and compare its performance with the performance in the litterature. To achieve that, we trained three classical models: A basic Convolutional neural network, a VGG Architechture and a Resnet Architechture. The pros of this method is that we don't need any external ressources during the training. However, the lack of data makes it very hard to obtain acceptable performances. But we can see that the used architechture can help improve performances, like with the Resnet Architechture. \n",
    "\n",
    "The second idea was to use Transfer Learning technics. We could see that using pre-trained weights helped the model to achieve better performances (35% with a pre-trained Resnet 18). However, we couldn't achieve comparable performances by using the features extracted by the Discriminator af a DCGAN Architechture. This technic has its limits since it depends on the generalization of the original dataset and the aaptability of the problem. \n",
    "\n",
    "The third idea was to incorpore a priori, or to use other knowledge that we have on our data. We did that through transformation on the data. But we coud see that it didn't improve the results by much. However, it acted as a regularization of the training, which mean that we may achiev better performances by training more the models (Which wasn't done due to lack of performances).\n",
    "\n",
    "We can see here the performances of each technic:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 631.75x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "methods = ['CNN' , 'Resnet' , 'VGG' , 'Pretrained Resnet' , 'DCGAN' , 'Transformation + Resnet' , \n",
    "           'Transformation + VGG' , 'ScatteringResnet']\n",
    "\n",
    "train_performance = [1 , .75 , .17 , 1 , 1 , .42 , .11 , .85]\n",
    "test_performance = [.28 , .18 , .1 , .35 , .21 , .18 , .10 , .19]\n",
    "\n",
    "df['method'] = methods + methods\n",
    "df['type'] = ['train']*len(methods) + ['test']*len(methods)\n",
    "df['performance'] = train_performance + test_performance\n",
    "\n",
    "sns.factorplot(y='method', x='performance', hue='type', data=df, kind='bar' , size = 4 , aspect = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve our results, we can combine all these technics into a single one. We can also use weak supervision technics to improve the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
